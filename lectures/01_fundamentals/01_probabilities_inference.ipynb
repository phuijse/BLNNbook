{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities and inference\n",
    "\n",
    "Disclaimer: This notebook is not comprehensive. It only works as a reminder of the fundamental concepts from probability theory and statistical inference needed in this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic concepts from probability theory\n",
    "\n",
    "**Random/Stochastic Variable (RV)**\n",
    "\n",
    "A variable that maps the output of a random process, e.g. *throwing a coin/dice, predicting weather*. Tipically denoted by a capital letter: $X$\n",
    "\n",
    "We don't know its value until we draw or sample from it. Sampling is equivalent to observing the RV. Observations are typically denoted with lowercase letters: $x \\sim X$\n",
    "\n",
    "We describe a RV by its domain and probability density/mass function\n",
    "\n",
    "**Calisthenics:** Fair six-faced dice\n",
    "\n",
    "Domain (possible outputs): $[1, 2, 3, 4, 5, 6]$ \n",
    "\n",
    "Probability mass function: $\\left[\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}\\right]$\n",
    "\n",
    "- The probability of drawing a $1$ is $P(X=1) = P(1) = \\frac{1}{6}$\n",
    "- The probability of drawing a number greater or equal than $5$ is $P(X\\geq 5) = \\frac{1}{3}$\n",
    "- The probability of drawing and odd number is $P(\\text{odd}) = \\frac{1}{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joint, Marginal and Conditional probabilities**\n",
    "\n",
    "If we have two or more random variables we can define their joint pmf: $P(X,Y)$\n",
    "\n",
    "From the joint we sum (integrate) to obtain the marginal distribution of $X$ or $Y$\n",
    "\n",
    "**Law of total probability (sum rule):**\n",
    "\n",
    "If we sum on X we obtain the marginal for $Y$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(Y=y) &= \\sum_{x \\in \\mathcal{X}} P(X=x, Y=y) \\nonumber \\\\\n",
    "&= \\sum_{x \\in \\mathcal{X}} P(Y=y|X=x) P(X=x),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $P(Y=y|X=x)$ is the conditional probability of $y$ given $x$\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "(iif $P(X=x) \\neq 0$)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows the joint PMF of a two dimensional discrete RV\n",
    "\n",
    "If we some in either axis we obtain the marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-4, 5, 1); y = np.arange(-4, 5, 1)\n",
    "X, Y = np.meshgrid(x, y); XY = np.zeros_like(X)\n",
    "XY[2:-2, -3] = 1; XY[2:-2, 2] = 1; XY[4, 2:-2] = 1\n",
    "XY = XY/np.sum(XY)\n",
    "\n",
    "data = hv.Dataset((x, y, XY), kdims=['x','y'], vdims='xy')\n",
    "joint = data.to(hv.Image).opts(cmap='Blues', width=300, height=300)\n",
    "margx = joint.reduce(x=np.sum).opts(interpolation='steps-mid').to(hv.Bars)\n",
    "margy = joint.reduce(y=np.sum).opts(interpolation='steps-mid').to(hv.Bars)\n",
    "(joint << margx.opts(width=150) << margy.opts(height=150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a horizontal slice of the joint we obtain the conditional $p(x|y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(hv.Bars, 'x').opts(title='p(x|y)', width=350, height=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a vertical slice would be the conditional $p(y|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(hv.Bars, 'y').opts(title='p(y|x)', width=350, height=200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chain rule of probabilities (product rule):**\n",
    "\n",
    "For example if we have four variables:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_1, x_2, x_3, x_4) &= P(x_4|x_3, x_2, x_1) P(x_3, x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2 |x_1) P(x_1) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "**Bayes Theorem:**\n",
    "\n",
    "Combining the product and sum rule for two random variables we can write\n",
    "\n",
    "$$\n",
    "P(y | x) = \\frac{P(x|y) P(y)}{P(x)} = \\frac{P(x|y) P(y)}{\\sum_{y\\in\\mathcal{Y}} P(x|y) P(y)}\n",
    "$$\n",
    "\n",
    "We call $P(y|x)$ the **posterior** distribution of $y$: \n",
    "\n",
    "> What we know of $y$ after we observe $x$ \n",
    "\n",
    "We call $P(y)$ the **prior** distribution of $y$\n",
    "\n",
    "> What we know of $y$ before observing $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independence:**\n",
    "\n",
    "If two RVs are independent then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x, y)  &= P(y|x) P(x)\\nonumber \\\\\n",
    "&= P(y) P(x)\\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> Knowing that $x$ happened does not help me to know if $y$ happened\n",
    "\n",
    "**Conditional independence:**\n",
    "\n",
    "If two RVs are conditionally independent given a third one then\n",
    "\n",
    "$$\n",
    "P(x, y|z)  = P(x|z)P(y|z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentism and Bayesianism: The meaning of probability\n",
    "\n",
    "**Meaning 1:** We observe the outcome of a random experiment (event) several times and we count\n",
    "\n",
    "We flip a coin 5 times and get [x, x, o, x, o]\n",
    "\n",
    "- The probability of x is 3/5\n",
    "- The probability of o is 2/5\n",
    "\n",
    "We have estimated the probability from the **frequency** of x and o\n",
    "\n",
    "> This is called the **Frequentist** interpretation of probability\n",
    "\n",
    "**Meaning 2:** Probability is the **degree of belief** of an event\n",
    "\n",
    "Probabilities describe **assumptions** and also describe **inference given those assumptions**\n",
    "\n",
    "> This is called the **Bayesian** interpretation of probability\n",
    "\n",
    "Enough philosophy, What is the difference for us?\n",
    "\n",
    "- Intepretation of uncertainty\n",
    "- Incorporation of prior information\n",
    "- Model evaluation\n",
    "- Handling of nuisance parameters\n",
    "\n",
    "Specifically on inference\n",
    "\n",
    "- Frequentist: Write the likelihood, get its maximum: **parameters are point estimates**\n",
    "- Bayesian: Set priors and get posteriors: **parameters can be uncertain and have distributions too**\n",
    "\n",
    "Most of the time both paradigms will get to the same result, but intepretation can be different!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General definition\n",
    "\n",
    "> Drawing conclusions from facts/evidence through reasoning and scientific premises\n",
    "\n",
    "In our case\n",
    "\n",
    "> Find the most certain answer  based on data and a model \n",
    "\n",
    "- Our scientific premises and assumptions goes into the model\n",
    "- The facts are the data\n",
    "\n",
    "Tasks in statistical inference:\n",
    "\n",
    "- Level 1: Fit a model to the data\n",
    "- Level 2: Validate and compare between models\n",
    "- Level 3: Answer questions with our model: **Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: Fitting the parameters of a model\n",
    "\n",
    "### Maximum likelihood\n",
    "\n",
    "We have a model $\\mathcal{M}_j$ with parameters $\\theta$\n",
    "\n",
    "> We want to estimate $\\theta~$ that best fit the data $\\mathcal{D}$\n",
    "\n",
    "We start by writing Bayes Theorem\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "Let's name these terms for the future\n",
    "\n",
    "$$\n",
    "\\text{posterior} = \\frac{\\text{likelihood} \\cdot \\text{prior}}{\\text{evidence}}\n",
    "$$\n",
    "\n",
    "> In the **bayesian approach** we want to find the posterior of $\\theta~$\n",
    "\n",
    "But let's start with the following\n",
    "\n",
    "- We only care for a point estimate of $\\theta~$ \n",
    "- We assume that the prior on $\\theta~$ is uniform (uninformative) \n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is known as the **Maximum likelihood estimator (MLE)** of $\\theta~$\n",
    "\n",
    "**Important** Remember that likelihood is not the same as probability\n",
    "\n",
    "- If $\\theta~$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines a probability over $\\mathcal{D}$\n",
    "- If $\\mathcal{D}$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines the likelihood of $\\theta$\n",
    "\n",
    "MLE forms the basis of the **frequentist approach** for parameter estimation\n",
    "\n",
    "1. (Forget about Bayes theorem and) Propose a likelihood\n",
    "1. Get its arg maximum\n",
    "\n",
    "More details [here](https://github.com/magister-informatica-uach/INFO337) and in the course textbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** MLE for a coin\n",
    "\n",
    "<img src=\"https://c.tenor.com/bd3puNXKLwUAAAAd/coin-toss.gif\" width=\"200\">\n",
    "\n",
    "Let the following be observations from a \"coin toss\" process\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = [x_1, x_2, \\ldots, x_N]\n",
    "$$\n",
    "\n",
    "where $x_i \\in \\{0: \\text{tail}, 1: \\text{head}\\}$\n",
    "\n",
    "**Assumption 1:** Observations are **independent and identically distributed (iid)**\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) = \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j)\n",
    "$$\n",
    "\n",
    "**Assumption 2:** [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) model with parameter $\\theta \\in [0, 1]$ for the observations\n",
    "\n",
    "$$\n",
    "p(x_i|\\theta, \\mathcal{M}_j) = \\theta^{x_i} (1- \\theta)^{1-x_i}\n",
    "$$\n",
    "\n",
    "This is a distribution for binary outcomes $x\\in \\{0, 1\\}$. Explore how the distribution change with $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap(kdims='Parameter')\n",
    "x = [0, 1]\n",
    "for theta in np.linspace(0, 1, num=8):\n",
    "    dist = scipy.stats.bernoulli(p=theta)\n",
    "    hmap[theta] = hv.Bars((x, [dist.pmf(k) for k in x]), 'x', 'PMF', label='Bernoulli distribution,')\n",
    "\n",
    "hmap.opts(hv.opts.Bars(width=450, height=300, tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What is the MLE of $\\theta~$?\n",
    "\n",
    "**Trick of the trade:** The arg maximum of $p(x)$ is the same as $\\log p(x)$\n",
    "\n",
    "With this we can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "From here we can take the derivate, set it to zero, and get the MLE \n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors and Maximum a Posteriori\n",
    "\n",
    "Let's lift the assumption that the prior is uniform \n",
    "\n",
    "- We are still looking for a point estimate of $\\theta~$ \n",
    "- We keep the *iid* assumption and we consider the \"log trick\"\n",
    "\n",
    "We can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) + \\log p(\\theta|\\mathcal{M}_j) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is called the **Maximum a posteriori (MAP)** estimate of $\\theta~ $\n",
    "\n",
    "The MAP estimate corresponds to the mode of $p(\\theta|\\mathcal{D}, \\mathcal{M}_j)$\n",
    "\n",
    "Now, in addition to the model (likelihood), we have to set the prior $p(\\theta)$. Note that this can be a [sensible choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** MAP for the coin\n",
    "\n",
    "We will use a [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution) prior for the Bernoulli parameter $\\theta ~$\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where $B(x,y) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ and $\\Gamma(x)$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function)\n",
    "\n",
    "This is a distribution for $x \\in [0, 1]$, *e.g* probabilities. For $\\alpha=\\beta=1$ we get the Uniform distribution in $[0, 1]$. \n",
    "\n",
    "Explore how the beta distribution change with $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, num=100)\n",
    "hmap = hv.HoloMap(kdims=['alpha', 'beta'])\n",
    "for a in [0.5, 1, 2, 3, 10]:\n",
    "    for b in [0.5, 1, 2, 3, 10]:\n",
    "        dist = scipy.stats.beta(a, b)\n",
    "        hmap[(a,b)] = hv.Curve((x, dist.pdf(x)), 'x', 'PDF', label='Beta distribution,')\n",
    "\n",
    "hmap.opts(hv.opts.Curve(width=450, height=300, ylim=(0, 5), tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace the distributions of choice in the MAP omitting the terms that do not depend on $\\theta~$\n",
    "\n",
    "$$\n",
    "\\hat \\theta= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) +(\\alpha -1) \\log(\\theta) + ( \\beta -1) \\log(1-\\theta) \n",
    "$$\n",
    "\n",
    "if we set the derivative to zero we obtain\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N+\\alpha - \\beta} \\left(\\alpha -1 + \\sum_{i=1}^N x_i\\right)\n",
    "$$\n",
    "\n",
    "Note that this solution reduces to the MLE for $\\alpha=\\beta=1$ (uniform)\n",
    "\n",
    "> If we know something about the coin before observing the data we add it through $\\alpha$ and $\\beta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian inference\n",
    "\n",
    "With MLE we get point estimates\n",
    "\n",
    "> How good are these estimates? Can we trust them? What is their uncertainty?\n",
    "\n",
    "Following a frequentist approach we answer this through confidence intervals/bootstrap\n",
    "\n",
    "In a \"full\" bayesian approach we select likelihood/prior and aim for the posterior of $\\theta~$,\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "If we have the posterior we know everything about $\\theta~$. But, how do we get the posterior?\n",
    "\n",
    "**Simple case: Analytical posterior**\n",
    "\n",
    "In some \"very special cases\" the posterior is analytically tractable. Let's go back to our example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Posterior for the coin\n",
    "\n",
    "The likelihood of the coin (Bernoulli) is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) &= \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\prod_{i=1}^N \\theta^{x_i} (1-\\theta)^{1-x_i} \\nonumber \\\\\n",
    "&= \\theta^{\\sum_i x_i}(1-\\theta)^{N-\\sum_i x_i} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The prior is Beta\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha , \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "Then the posterior is\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{1}{Z} \\theta^{\\alpha +\\sum_i x_i - 1}(1-\\theta)^{\\beta +N-\\sum_i x_i-1},\n",
    "$$\n",
    "where $Z$ is a normalizing constant\n",
    "\n",
    "We can recognize that the posterior is also Beta:\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\text{Beta}(\\theta| \\hat \\alpha , \\hat \\beta),\n",
    "$$\n",
    "\n",
    "with parameters $\\hat \\alpha= \\alpha +\\sum_i x_i$ and $\\hat \\beta= \\beta +N-\\sum_i x_i$\n",
    "\n",
    "In this case we say that Beta is **conjugate** to the Bernoulli distribution: It produces a Beta posterior\n",
    "\n",
    "See the following article for a table of [conjugate pairs](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactive posterior:** Move the sliders to change $\\alpha$, $\\beta$ and the number of coins observed\n",
    "\n",
    "How many coins do we need to observe so that the posterior gets close to $p=.7$?\n",
    "\n",
    "What is the influence of $\\alpha$ and $\\beta$ when $N$ is low? And when $N$ is high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coins = scipy.stats.bernoulli.rvs(p=0.7, size=1000, random_state=1234) # True parameter is 0.7\n",
    "x = np.linspace(0, 1, num=100)\n",
    "hmap1 = hv.HoloMap(kdims=['N'])\n",
    "hmap2 = hv.HoloMap(kdims=['N', 'alpha', 'beta'])\n",
    "for N in [1, 2, 5, 10, 20, 50, 100, 200, 500]:\n",
    "    heads = np.sum(coins[:N]) \n",
    "    hmap1[N] = hv.Bars((['head','tail'], [heads, N-heads]), 'x', 'Histogram', label='Coins')\n",
    "    for a in [0.5, 2, 10]:\n",
    "        for b in [0.5, 2, 10]:\n",
    "            prior = scipy.stats.beta(a, b)\n",
    "            posterior = scipy.stats.beta(a + heads, b + N - heads)\n",
    "            hprior = hv.Curve((x, prior.pdf(x)), 'x', 'PDF', group='Distribution', label='prior')\n",
    "            hposterior = hv.Curve((x, posterior.pdf(x)), 'x', 'PDF', group='Distribution', label='posterior')\n",
    "            hmap2[(N, a, b)] = hprior*hposterior\n",
    "\n",
    "#hv.output(widget_location='bottom')\n",
    "(hmap1+hmap2).opts(hv.opts.Bars(width=150, height=300),\n",
    "                   hv.opts.Curve(width=300, height=300, ylim=(0, 5), tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the Bayesian approach online problems are just updates to the posterior\n",
    "\n",
    "The following animation shows how the previous posterior can be iteratively updated as new data arrives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, num=100)\n",
    "hmap1 = hv.HoloMap(kdims=['Iteration'])\n",
    "hmap2 = hv.HoloMap(kdims=['Iteration'])\n",
    "\n",
    "a = b = 1 # prior belief\n",
    "for k, coin in enumerate(coins[:100]):\n",
    "    hmap1[k] = hv.Bars((['head','tail'], [a-1, b-1]), 'x', 'Histogram', label='Coins')\n",
    "    hmap2[k] = hv.Curve((x, scipy.stats.beta(a, b).pdf(x)), 'x', 'PDF', label='Posterior')\n",
    "    # posterior updates\n",
    "    a += coin\n",
    "    b += 1 - coin\n",
    "    \n",
    "(hmap1+hmap2).opts(hv.opts.Bars(width=300, height=300),\n",
    "                   hv.opts.Curve(width=400, height=300, ylim=(0, 5)))\n",
    "hv.output((hmap1+hmap2), holomap='gif', fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What  if I can't get an analytical posterior?\n",
    "\n",
    "In many cases the denominator in the posterior \n",
    "\n",
    "$$\n",
    "p(\\mathcal{D} | \\mathcal{M_j}) = \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "$$\n",
    "\n",
    "is intractable\n",
    "\n",
    "The options are to\n",
    "\n",
    "1. Approximation based: Variational Inference (VI)\n",
    "1. Sampling based: Markov Chain Monte Carlo (MCMC) \n",
    "\n",
    "We will review how to implement both using `pyro` in the next chapter of this course \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Inference: Comparing models\n",
    "\n",
    "Using Bayes theorem we can express the posterior probability of a given model as\n",
    "\n",
    "$$\n",
    "p(\\mathcal{M_j} | \\mathcal{D}) = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D})}\n",
    "$$\n",
    "\n",
    "where $p(\\mathcal{D} | \\mathcal{M_j})$ is called the **evidence**  or the **marginal likelihood** for $\\mathcal{M_j}$\n",
    "\n",
    "The evidence was ignored in level 1 inference (normalizing constant) but in this level is key!\n",
    "\n",
    "If we want to compare two models we can compute the ratio between posteriors \n",
    "\n",
    "$$\n",
    "\\frac{p(\\mathcal{M_j} | \\mathcal{D})}{p(\\mathcal{M_k} | \\mathcal{D})} = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D} | \\mathcal{M_k})  p(\\mathcal{M_k})}\n",
    "$$\n",
    "\n",
    "For example we may ignore the priors if we consider the models to be equally probable or we can use the priors to favor simpler models and implement **Occam's Razor (principle of parsinomy)**\n",
    "\n",
    "If there are many models and we care only for the most probable we can write\n",
    "\n",
    "$$\n",
    "\\mathcal{M}^* = \\text{arg} \\max_j p(\\mathcal{M_j} | \\mathcal{D}) \n",
    "$$\n",
    "\n",
    "Using Bayes Theorem and assuming that all models are equally probable (uniform prior)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{M}^* &= \\text{arg} \\max_j p(\\mathcal{D} | \\mathcal{M_j}) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_j \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-study and recommended reading\n",
    "\n",
    "- More on [Frequentism vs Bayesianism](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/)\n",
    "- More on level 2 inference: [Chapter 28 of D. Mackay's book](http://www.inference.org.uk/mackay/itprnn/book.html) and [Chapter 12 of D.Barber's book]()\n",
    "- More on sampling and MCMC: [Chapter 27 of D. Barber's book](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
