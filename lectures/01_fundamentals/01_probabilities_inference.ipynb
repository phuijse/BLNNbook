{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<!-- Mejorar visualizaciÃ³n en proyector -->\n",
    "<style>\n",
    ".rendered_html {font-size: 1.2em; line-height: 150%;}\n",
    "div.prompt {min-width: 0ex; padding: 0px;}\n",
    ".container {width:95% !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%autosave 0\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from functools import partial\n",
    "slider_layout = widgets.Layout(width='600px', height='20px')\n",
    "slider_style = {'description_width': 'initial'}\n",
    "IntSlider_nice = partial(widgets.IntSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "FloatSlider_nice = partial(widgets.FloatSlider, style=slider_style, layout=slider_layout, continuous_update=False)\n",
    "SelSlider_nice = partial(widgets.SelectionSlider, style=slider_style, layout=slider_layout, continuous_update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random/Stochastic Variable (RV)\n",
    "\n",
    "A variable that maps the output of a random process: *throwing a coin/dice, predicting weather*\n",
    "- Denoted by a capital letter: $X$\n",
    "\n",
    "We don't know its value until we draw/sample from it: We observe the RV\n",
    "- Observations are denoted with lowercase letters: $x \\sim X$\n",
    "\n",
    "We describe a RV through its domain and probability density/mass function\n",
    "\n",
    "##### Calisthenics: Fair six-faced dice\n",
    "\n",
    "Domain (possible outputs): $[1, 2, 3, 4, 5, 6]$ with probability mass function: $[\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}]$\n",
    "\n",
    "- The probability of drawing a $1$ is $P(X=1) = P(1) = \\frac{1}{6}$\n",
    "- The probability of drawing a number greater or equal than $5$ is $P(X\\geq 5) = \\frac{1}{3}$\n",
    "- The probability of drawing and odd number is $P(\\text{odd}) = \\frac{1}{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint, Marginal and Conditional probabilities\n",
    "\n",
    "If we have two or more random variables we can define their joint pdf/pmf: $P(X,Y)$\n",
    "\n",
    "From the joint we sum to obtain the marginal of $X$ or $Y$. This is the:\n",
    "\n",
    "**Law of total probability (sum rule)**:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(Y=y) &= \\sum_{x \\in \\mathcal{X}} P(X=x, Y=y) \\nonumber \\\\\n",
    "&= \\sum_{x \\in \\mathcal{X}} P(Y=y|X=x) P(X=x),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $P(Y=y|X=x)$ is the conditional probability of $y$ given $x$\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "(iif $P(X=x) \\neq 0$)\n",
    "\n",
    "this is a special case of the \n",
    "\n",
    "**Chain rule of probabilities (product rule)**:\n",
    "\n",
    "For example with four variables:\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_1, x_2, x_3, x_4) &= P(x_4|x_3, x_2, x_1) P(x_3, x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2 |x_1) P(x_1) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Bayes Theorem\n",
    "\n",
    "Combining the product and sum rule for two random variables we can write\n",
    "\n",
    "\n",
    "$$\n",
    "P(y | x) = \\frac{P(x|y) P(y)}{P(x)} = \\frac{P(x|y) P(y)}{\\sum_{y\\in\\mathcal{Y}} P(x|y) P(y)}\n",
    "$$\n",
    "\n",
    "We call $P(y|x)$ the **posterior** distribution of $y$: \n",
    "> What we know of $y$ after we observe $x$ \n",
    "\n",
    "We call $P(y)$ the **prior** distribution of $y$\n",
    "> What we know of $y$ before observing $x$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8.5, 3.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.view_init(elev=45., azim=-45)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "x = np.arange(-4, 5, 1); y = np.arange(-4, 5, 1)\n",
    "X, Y = np.meshgrid(x, y); XY = np.zeros_like(X)\n",
    "XY[-3, 2:-2] = 1; XY[2, 2:-2] = 1; XY[2:-2, 4] = 1\n",
    "XY = XY/np.sum(XY)\n",
    "\n",
    "def update_plot(x_cond):\n",
    "    ax.cla()\n",
    "    ax.bar(x, np.sum(XY, axis=1), zdir='x', color='b', zs=-4)\n",
    "    ax.bar(y, np.sum(XY, axis=0), zdir='y', color='r', zs=5)\n",
    "    colors = np.array([['m']*len(x)]*len(y))\n",
    "    colors[:, x_cond-5] = 'b'\n",
    "    ax.bar3d(X.ravel(), Y.ravel(), np.zeros_like(XY.ravel()), 1, 1, XY.ravel(), color=colors.ravel())\n",
    "    ax.set_xlim([-4, 5]); ax.set_xlabel('X')\n",
    "    ax.set_ylim([-4, 5]); ax.set_ylabel('Y')\n",
    "    ax2.cla()\n",
    "    ax2.bar(y, XY[X==x_cond]/(1e-8 + np.sum(XY[X==x_cond])), color='b')\n",
    "    ax2.set_title(\"P(Y|X={0})\".format(x_cond))\n",
    "    ax2.set_ylim([0, 0.55])\n",
    "    ax2.set_xlim([-4, 4])\n",
    "    \n",
    "widgets.interact(update_plot, x_cond=IntSlider_nice(min=-4, max=4, value=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independence**\n",
    "\n",
    "If two RVs are independent then\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x, y)  &= P(y|x) P(x)\\nonumber \\\\\n",
    "&= P(y) P(x)\\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> Knowing that $x$ happened does not help me to know if $y$ happened\n",
    "\n",
    "**Conditional independence**\n",
    "\n",
    "If two RVs are conditionally independent given a third one then\n",
    "$$\n",
    "P(x, y|z)  = P(x|z)P(y|z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The meaning of probability\n",
    "\n",
    "**Meaning 1:** We observe the outcome of a random experiment (event) several times and we count\n",
    "\n",
    "We flip a coin 5 times and get [x, x, o, x, o]\n",
    "\n",
    "- The probability of x is 3/5\n",
    "- The probability of o is 2/5\n",
    "\n",
    "We have estimated the probability from the **frequency** of x and o\n",
    "\n",
    "> This is called the **Frequentist** interpretation of probability\n",
    "\n",
    "**Meaning 2:** Probability is the **degree of belief** of an event\n",
    "\n",
    "Probabilities describe **assumptions** and also describe **inference given those assumptions**\n",
    "\n",
    "> This is called the **Bayesian** interpretation of probability\n",
    "\n",
    "##### Enough philosophy, What is the difference for us?\n",
    "- Intepretation of uncertainty\n",
    "- Incorporation of prior information\n",
    "- Model evaluation\n",
    "- Handling of nuisance parameters\n",
    "\n",
    "Specifically on inference\n",
    "- Frequentist: Write the likelihood, get its maximum: **parameters are point estimates**\n",
    "- Bayesian: Set priors and get posteriors: **parameters can be uncertain and have distributions too**\n",
    "\n",
    "Most of the time both paradigms will get to the same result, but intepretation can be different!\n",
    "\n",
    "More on [Frequentism vs Bayesianism](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General definition\n",
    "\n",
    "> Drawing conclusions from facts/evidence through reasoning and scientific premises\n",
    "\n",
    "In our case\n",
    "\n",
    "> Find the most certain answer  based on data and a model \n",
    "\n",
    "- Our scientific premises and assumptions goes into the model\n",
    "- The facts are the data\n",
    "\n",
    "### Tasks in statistical inference\n",
    "\n",
    "- Level 1: Fit a model to the data\n",
    "- Level 2: Validate and compare between models\n",
    "- Level 3: Answer questions with our model: **Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1: Fitting the parameters of a model\n",
    "\n",
    "We have a model $\\mathcal{M}_j$ with parameters $\\theta$\n",
    "\n",
    "> We want to estimate $\\theta~$ that best fit the data $\\mathcal{D}$\n",
    "\n",
    "We start by writing Bayes Theorem\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "Let's name these terms for the future\n",
    "$$\n",
    "\\text{posterior} = \\frac{\\text{likelihood} \\cdot \\text{prior}}{\\text{evidence}}\n",
    "$$\n",
    "\n",
    "> In the **bayesian approach** we want to find the posterior of $\\theta~$\n",
    "\n",
    "But let's start with the following\n",
    "\n",
    "- We only care for a point estimate of $\\theta~$ \n",
    "- We assume that the prior on $\\theta~$ is uniform (uninformative) \n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is known as the **Maximum likelihood estimator (MLE)** of $\\theta~$\n",
    "\n",
    "\n",
    "**Important** Likelihood is not the same as probability\n",
    "- If $\\theta~$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines a probability over $\\mathcal{D}$\n",
    "- If $\\mathcal{D}$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines the likelihood of $\\theta$\n",
    "\n",
    "MLE forms the basis of the **frequentist approach** for parameter estimation\n",
    "1. (Forget about Bayes theorem and) Propose a likelihood\n",
    "1. Get its arg maximum\n",
    "\n",
    "More details [here](https://github.com/magister-informatica-uach/INFO337) and course textbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Bernoulli distribution\n",
    "\n",
    "A distribution for binary outcomes $x\\in \\{0, 1\\}$\n",
    "\n",
    "The pmf is\n",
    "$$\n",
    "p(x|p) = \\begin{cases} p & \\text{if } x=1 \\\\ 1-p & \\text{if } x=0  \\end{cases}\n",
    "$$\n",
    "\n",
    "which can be written as \n",
    "$$\n",
    "p(x|p) = p^x (1-p)^{1-x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "@widgets.interact(p=FloatSlider_nice(min=0, max=1, value=0.5, step=0.1))\n",
    "def update(p):\n",
    "    x = scipy.stats.bernoulli.rvs(p, size=1000)\n",
    "    ax.cla()\n",
    "    ax.hist(x, density=True, range=(0, 1), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE for a coin\n",
    "\n",
    "Observations from a coin \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = [x_1, x_2, \\ldots, x_N]\n",
    "$$\n",
    "\n",
    "where $x_i \\in \\{0, 1\\}$\n",
    "\n",
    "**Assumption 1:** Observations are **independent and identically distributed (iid)**\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) = \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j)\n",
    "$$\n",
    "\n",
    "**Assumption 2:** Bernoulli model with parameter $\\theta \\in [0, 1]$ for the observations\n",
    "\n",
    "$$\n",
    "p(x_i|\\theta, \\mathcal{M}_j) = \\theta^{x_i} (1- \\theta)^{1-x_i}\n",
    "$$\n",
    "\n",
    "\n",
    "> What is the MLE of $\\theta~$?\n",
    "\n",
    "**Trick of the trade:** The arg maximum of $p(x)$ is the same as $\\log p(x)$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can take the derivate, set it to zero, and get the MLE \n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors and Maximum a Posteriori\n",
    "\n",
    "Let's lift the assumption that the prior is uniform \n",
    "\n",
    "- We are still looking for a point estimate of $\\theta~$ \n",
    "- We keep the *iid* assumption and we consider the \"log trick\"\n",
    "\n",
    "We can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) + \\log p(\\theta|\\mathcal{M}_j) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is called the **Maximum a posteriori (MAP)** estimate of $\\theta~ $\n",
    "\n",
    "The MAP estimate corresponds to the mode of $p(\\theta|\\mathcal{D}, \\mathcal{M}_j)$\n",
    "\n",
    "#### In addition to the model (likelihood) we have to set the prior $p(\\theta)$\n",
    "\n",
    "This can be a [sensible choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Beta distribution\n",
    "\n",
    "A distribution for $x \\in [0, 1]$, *e.g* probabilities\n",
    "\n",
    "The pdf is \n",
    "\n",
    "$$\n",
    "\\text{Beta}(x|\\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where $B(x,y) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ and $\\Gamma(x)$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function)\n",
    "\n",
    "For $\\alpha=\\beta=1$ we get the Uniform distribution in $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "@widgets.interact(alpha=FloatSlider_nice(min=0.001, max=10, value=1, step=0.1), \n",
    "                  beta=FloatSlider_nice(min=0.001, max=10, value=1, step=0.1))\n",
    "def update(alpha, beta):\n",
    "    x = scipy.stats.beta.rvs(alpha, beta, size=1000)\n",
    "    ax.cla()\n",
    "    ax.hist(x, density=True, range=(0, 1), bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map for the coin\n",
    "\n",
    "\n",
    "We will use a Beta prior for $\\theta ~$\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "Omitting the terms that do not depend on $\\theta~$ we get the MAP \n",
    "$$\n",
    "\\hat \\theta= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) +(\\alpha -1) \\log(\\theta) + ( \\beta -1) \\log(1-\\theta) \n",
    "$$\n",
    "\n",
    "By setting the derivate to zero we obtain\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N+\\alpha - \\beta} (\\alpha -1 + \\sum_{i=1}^N x_i)\n",
    "$$\n",
    "\n",
    "Note that it reduces to the MLE for $\\alpha=\\beta=1$ (uniform)\n",
    "\n",
    "\n",
    "> If we know something about the coin before observing the data we add it through $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference\n",
    "\n",
    "With MLE we get point estimates\n",
    "\n",
    "> How good are these estimates? Can we trust them? What is their uncertainty?\n",
    "\n",
    "Following a frequentist approach we answer this through confidence intervals/bootstrap\n",
    "\n",
    "In a \"full\" bayesian approach we select likelihood/prior and aim for the posterior of $\\theta~$,\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "> If we have the posterior we know everything about $\\theta~$\n",
    "\n",
    "But, how do we get the posterior?\n",
    "\n",
    "### Analytical posterior\n",
    "\n",
    "In some \"very special cases\" the posterior is analytically tractable\n",
    "\n",
    "Enter the [**conjugate priors**](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posterior for the coin\n",
    "\n",
    "\n",
    "The likelihood of the coin (Bernoulli) is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) &= \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\prod_{i=1}^N \\theta^{x_i} (1-\\theta)^{1-x_i} \\nonumber \\\\\n",
    "&= \\theta^{\\sum_i x_i}(1-\\theta)^{N-\\sum_i x_i} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The prior is Beta\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha , \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "The posterior is\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{1}{Z} \\theta^{\\alpha +\\sum_i x_i - 1}(1-\\theta)^{\\beta +N-\\sum_i x_i-1},\n",
    "$$\n",
    "where $Z$ is a normalizing constant\n",
    "\n",
    "We recognize that the posterior is also Beta:\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\text{Beta}(\\theta| \\hat \\alpha , \\hat \\beta),\n",
    "$$\n",
    "\n",
    "with $\\hat \\alpha= \\alpha +\\sum_i x_i$ and $\\hat \\beta= \\beta +N-\\sum_i x_i$\n",
    "\n",
    "> We say that Beta is conjugate to the Bernoulli distribution: It produces a Beta posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Influence of $\\alpha$, $\\beta$ and the number of observations from the coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = scipy.stats.bernoulli.rvs(p=0.7, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_plot = np.linspace(0, 1, num=1000)\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "\n",
    "def update_plot(N, a, b):\n",
    "    ax.cla()\n",
    "    # Beta(a, b)\n",
    "    prior = scipy.stats.beta(a, b)\n",
    "    p = np.sum(coins[:N])\n",
    "    # Bernoulli\n",
    "    likelihood = (p_plot**p)*(1-p_plot)**(N-p)\n",
    "    likelihood = likelihood*1000/np.sum(likelihood)\n",
    "    # Beta(hat a, hat b)\n",
    "    posterior = scipy.stats.beta(a + np.sum(coins[:N]), b + N - np.sum(coins[:N]))\n",
    "    ax.plot(p_plot, prior.pdf(p_plot), label='prior')\n",
    "    ax.plot(p_plot, likelihood, label='likelihood')\n",
    "    ax.plot(p_plot, posterior.pdf(p_plot), label='posterior')\n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "widgets.interact(update_plot, N=SelSlider_nice(options=[1, 2, 5, 10, 20, 50, 100, 200, 500]),\n",
    "                 a=FloatSlider_nice(min=0.0, max=10, value=1),\n",
    "                 b=FloatSlider_nice(min=0.0, max=10, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian approach online problems are just updates to the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "a = b = 1\n",
    "\n",
    "def update_plot(k):\n",
    "    ax.cla()\n",
    "    ax.plot(p_plot, scipy.stats.beta(a + np.sum(coins[:k]), \n",
    "                                     b + k - np.sum(coins[:k])).pdf(p_plot), label=str(k))\n",
    "    ax.set_title(k)\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=1000, interval=200, \n",
    "                               repeat=True, blit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What  if I can't get an analytical posterior\n",
    "\n",
    "In many cases the denominator in the posterior \n",
    "\n",
    "$$\n",
    "p(\\mathcal{D} | \\mathcal{M_j}) = \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "$$\n",
    "is intractable\n",
    "\n",
    "The options are to\n",
    "1. Use approximations: **Variational Inference** (TO BE CONTINUED)\n",
    "1. Use Markov Chain Monte Carlo (MCMC) (NOT IN THIS COURSE)\n",
    "\n",
    "##### MCMC using pyro\n",
    "\n",
    "- [MCMC docs](https://docs.pyro.ai/en/0.2.1-release/mcmc.html)\n",
    "- [Distributions docs](https://docs.pyro.ai/en/0.2.1-release/distributions.html)\n",
    "- [More complete example](https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.mcmc.api import MCMC\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.distributions import Beta, Bernoulli, Gamma\n",
    "\n",
    "def model(data):\n",
    "    alpha = pyro.sample('alpha', Gamma(2, 0.1))\n",
    "    beta = pyro.sample('beta', Gamma(2, 0.1))\n",
    "    theta = pyro.sample('theta', Beta(alpha, beta))\n",
    "    y = pyro.sample('data', Bernoulli(probs=theta), obs=data)\n",
    "    return y\n",
    "\n",
    "nuts_kernel = NUTS(model, adapt_step_size=True)\n",
    "mcmc = MCMC(nuts_kernel, num_chains=2, num_samples=1000, warmup_steps=100)\n",
    "mcmc.run(torch.from_numpy(coins.astype('float32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(mcmc.diagnostics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 3))\n",
    "ax.hist(mcmc.get_samples()['theta'].numpy(), density=True)\n",
    "ax.set_xlim([0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2: Comparing models\n",
    "\n",
    "Using Bayes theorem we can express the posterior probability of a given model as\n",
    "\n",
    "$$\n",
    "p(\\mathcal{M_j} | \\mathcal{D}) = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D})}\n",
    "$$\n",
    "\n",
    "> $p(\\mathcal{D} | \\mathcal{M_j})$ is called the **evidence**  or the **marginal likelihood** for $\\mathcal{M_j}$\n",
    "\n",
    "The evidence was ignored in level 1 inference (normalizing constant) but in this level is key!\n",
    "\n",
    "If we want to compare two models we can compute the ratio between posteriors \n",
    "\n",
    "$$\n",
    "\\frac{p(\\mathcal{M_j} | \\mathcal{D})}{p(\\mathcal{M_k} | \\mathcal{D})} = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D} | \\mathcal{M_k})  p(\\mathcal{M_k})}\n",
    "$$\n",
    "\n",
    "- We may ignore the priors if we consider the models to be equally probable\n",
    "- or we can use the priors to favor simpler models: **Occam Razor**\n",
    "\n",
    "If there are many models and we care only for the most probable we can write\n",
    "\n",
    "$$\n",
    "\\mathcal{M}^* = \\text{arg} \\max_j p(\\mathcal{M_j} | \\mathcal{D}) \n",
    "$$\n",
    "\n",
    "Using Bayes Theorem and assuming that all models are equally probable (uniform prior)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{M}^* &= \\text{arg} \\max_j p(\\mathcal{D} | \\mathcal{M_j}) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_j \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-study\n",
    "\n",
    "- More on level 2 inference: [Chapter 28 of D. Mackay's book](http://www.inference.org.uk/mackay/itprnn/book.html) and [Chapter 12 of D.Barber's book]()\n",
    "- More on sampling and MCMC: [Chapter 27 of D. Barber's book](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
