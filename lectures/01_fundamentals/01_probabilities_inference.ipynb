{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities and inference\n",
    "\n",
    "Disclaimer: This notebook is not comprehensive. It only works as a reminder of the fundamental concepts from probability theory and statistical inference needed in this course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic concepts from probability theory\n",
    "\n",
    "**Random/Stochastic Variable (RV)**\n",
    "\n",
    "A variable that maps the output of a random process, e.g. *throwing a coin/dice, predicting weather*. Tipically denoted by a capital letter: $X$\n",
    "\n",
    "We don't know its value until we draw or sample from it. Sampling is equivalent to observing the RV. Observations are typically denoted with lowercase letters: $x \\sim X$\n",
    "\n",
    "We describe a RV through its domain and probability density/mass function\n",
    "\n",
    "**Calisthenics:** Fair six-faced dice\n",
    "\n",
    "Domain (possible outputs): $[1, 2, 3, 4, 5, 6]$ with probability mass function: $\\left[\\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}, \\frac{1}{6}\\right]$\n",
    "\n",
    "- The probability of drawing a $1$ is $P(X=1) = P(1) = \\frac{1}{6}$\n",
    "- The probability of drawing a number greater or equal than $5$ is $P(X\\geq 5) = \\frac{1}{3}$\n",
    "- The probability of drawing and odd number is $P(\\text{odd}) = \\frac{1}{2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Joint, Marginal and Conditional probabilities**\n",
    "\n",
    "If we have two or more random variables we can define their joint pdf/pmf: $P(X,Y)$\n",
    "\n",
    "From the joint we sum to obtain the marginal of $X$ or $Y$. This is the:\n",
    "\n",
    "**Law of total probability (sum rule)**:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(Y=y) &= \\sum_{x \\in \\mathcal{X}} P(X=x, Y=y) \\nonumber \\\\\n",
    "&= \\sum_{x \\in \\mathcal{X}} P(Y=y|X=x) P(X=x),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $P(Y=y|X=x)$ is the conditional probability of $y$ given $x$\n",
    "\n",
    "$$\n",
    "P(Y=y|X=x) = \\frac{P(X=x, Y=y)}{P(X=x)}\n",
    "$$\n",
    "\n",
    "(iif $P(X=x) \\neq 0$)\n",
    "\n",
    "this is a special case of the \n",
    "\n",
    "**Chain rule of probabilities (product rule)**:\n",
    "\n",
    "For example with four variables:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x_1, x_2, x_3, x_4) &= P(x_4|x_3, x_2, x_1) P(x_3, x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2, x_1) \\nonumber \\\\\n",
    "&= P(x_4|x_3, x_2, x_1) P(x_3| x_2, x_1) P(x_2 |x_1) P(x_1) \\nonumber \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Bayes Theorem**\n",
    "\n",
    "Combining the product and sum rule for two random variables we can write\n",
    "\n",
    "$$\n",
    "P(y | x) = \\frac{P(x|y) P(y)}{P(x)} = \\frac{P(x|y) P(y)}{\\sum_{y\\in\\mathcal{Y}} P(x|y) P(y)}\n",
    "$$\n",
    "\n",
    "We call $P(y|x)$ the **posterior** distribution of $y$: \n",
    "\n",
    "> What we know of $y$ after we observe $x$ \n",
    "\n",
    "We call $P(y)$ the **prior** distribution of $y$\n",
    "\n",
    "> What we know of $y$ before observing $x$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive plot showing the joint, marginal and conditional distributions (only works locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import ipywidgets as widgets\n",
    "\n",
    "fig = plt.figure(figsize=(8.5, 3.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.view_init(elev=45., azim=-45)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "x = np.arange(-4, 5, 1); y = np.arange(-4, 5, 1)\n",
    "X, Y = np.meshgrid(x, y); XY = np.zeros_like(X)\n",
    "XY[-3, 2:-2] = 1; XY[2, 2:-2] = 1; XY[2:-2, 4] = 1\n",
    "XY = XY/np.sum(XY)\n",
    "\n",
    "def update_plot(x_cond):\n",
    "    ax.cla()\n",
    "    ax.bar(x, np.sum(XY, axis=1), zdir='x', color='b', zs=-4)\n",
    "    ax.bar(y, np.sum(XY, axis=0), zdir='y', color='r', zs=5)\n",
    "    colors = np.array([['m']*len(x)]*len(y))\n",
    "    colors[:, x_cond-5] = 'b'\n",
    "    ax.bar3d(X.ravel(), Y.ravel(), np.zeros_like(XY.ravel()), 1, 1, XY.ravel(), color=colors.ravel())\n",
    "    ax.set_xlim([-4, 5]); ax.set_xlabel('X')\n",
    "    ax.set_ylim([-4, 5]); ax.set_ylabel('Y')\n",
    "    ax2.cla()\n",
    "    ax2.bar(y, XY[X==x_cond]/(1e-8 + np.sum(XY[X==x_cond])), color='b')\n",
    "    ax2.set_title(\"P(Y|X={0})\".format(x_cond))\n",
    "    ax2.set_ylim([0, 0.55])\n",
    "    ax2.set_xlim([-4, 4])\n",
    "    \n",
    "widgets.interact(update_plot, x_cond=widgets.IntSlider(min=-4, max=4, value=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independence**\n",
    "\n",
    "If two RVs are independent then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(x, y)  &= P(y|x) P(x)\\nonumber \\\\\n",
    "&= P(y) P(x)\\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> Knowing that $x$ happened does not help me to know if $y$ happened\n",
    "\n",
    "**Conditional independence**\n",
    "\n",
    "If two RVs are conditionally independent given a third one then\n",
    "\n",
    "$$\n",
    "P(x, y|z)  = P(x|z)P(y|z)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The meaning of probability\n",
    "\n",
    "**Meaning 1:** We observe the outcome of a random experiment (event) several times and we count\n",
    "\n",
    "We flip a coin 5 times and get [x, x, o, x, o]\n",
    "\n",
    "- The probability of x is 3/5\n",
    "- The probability of o is 2/5\n",
    "\n",
    "We have estimated the probability from the **frequency** of x and o\n",
    "\n",
    "> This is called the **Frequentist** interpretation of probability\n",
    "\n",
    "**Meaning 2:** Probability is the **degree of belief** of an event\n",
    "\n",
    "Probabilities describe **assumptions** and also describe **inference given those assumptions**\n",
    "\n",
    "> This is called the **Bayesian** interpretation of probability\n",
    "\n",
    "Enough philosophy, What is the difference for us?\n",
    "\n",
    "- Intepretation of uncertainty\n",
    "- Incorporation of prior information\n",
    "- Model evaluation\n",
    "- Handling of nuisance parameters\n",
    "\n",
    "Specifically on inference\n",
    "\n",
    "- Frequentist: Write the likelihood, get its maximum: **parameters are point estimates**\n",
    "- Bayesian: Set priors and get posteriors: **parameters can be uncertain and have distributions too**\n",
    "\n",
    "Most of the time both paradigms will get to the same result, but intepretation can be different!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General definition\n",
    "\n",
    "> Drawing conclusions from facts/evidence through reasoning and scientific premises\n",
    "\n",
    "In our case\n",
    "\n",
    "> Find the most certain answer  based on data and a model \n",
    "\n",
    "- Our scientific premises and assumptions goes into the model\n",
    "- The facts are the data\n",
    "\n",
    "Tasks in statistical inference:\n",
    "\n",
    "- Level 1: Fit a model to the data\n",
    "- Level 2: Validate and compare between models\n",
    "- Level 3: Answer questions with our model: **Hypothesis testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1: Fitting the parameters of a model\n",
    "\n",
    "We have a model $\\mathcal{M}_j$ with parameters $\\theta$\n",
    "\n",
    "> We want to estimate $\\theta~$ that best fit the data $\\mathcal{D}$\n",
    "\n",
    "We start by writing Bayes Theorem\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "Let's name these terms for the future\n",
    "\n",
    "$$\n",
    "\\text{posterior} = \\frac{\\text{likelihood} \\cdot \\text{prior}}{\\text{evidence}}\n",
    "$$\n",
    "\n",
    "> In the **bayesian approach** we want to find the posterior of $\\theta~$\n",
    "\n",
    "But let's start with the following\n",
    "\n",
    "- We only care for a point estimate of $\\theta~$ \n",
    "- We assume that the prior on $\\theta~$ is uniform (uninformative) \n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is known as the **Maximum likelihood estimator (MLE)** of $\\theta~$\n",
    "\n",
    "**Important** Remember that likelihood is not the same as probability\n",
    "\n",
    "- If $\\theta~$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines a probability over $\\mathcal{D}$\n",
    "- If $\\mathcal{D}$ is fixed $p(\\mathcal{D}| \\theta, \\mathcal{M}_j)$ defines the likelihood of $\\theta$\n",
    "\n",
    "MLE forms the basis of the **frequentist approach** for parameter estimation\n",
    "\n",
    "1. (Forget about Bayes theorem and) Propose a likelihood\n",
    "1. Get its arg maximum\n",
    "\n",
    "More details [here](https://github.com/magister-informatica-uach/INFO337) and in the course textbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix:** [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n",
    "\n",
    "A distribution for binary outcomes $x\\in \\{0, 1\\}$\n",
    "\n",
    "The PMF is\n",
    "\n",
    "$$\n",
    "P(X=x|p) = p^x (1-p)^{1-x} = \\begin{cases} p & \\text{if } x=1 \\\\ 1-p & \\text{if } x=0  \\end{cases}\n",
    "$$\n",
    "\n",
    "How does this looks like for different values of the parameter $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMF(p, x=[0, 1]):\n",
    "    dist = scipy.stats.bernoulli(p=p)\n",
    "    return hv.Bars((x, [dist.pmf(k) for k in x]), 'x', 'PMF', label='Bernoulli distribution,')\n",
    "\n",
    "hmap = hv.HoloMap(kdims='Parameter p')\n",
    "for p in np.linspace(0, 1, num=7):\n",
    "    hmap[p] = PMF(p)\n",
    "\n",
    "hmap.opts(hv.opts.Bars(width=500, height=300, tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** MLE for a coin\n",
    "\n",
    "Observations from a coin \n",
    "\n",
    "$$\n",
    "\\mathcal{D} = [x_1, x_2, \\ldots, x_N]\n",
    "$$\n",
    "\n",
    "where $x_i \\in \\{0, 1\\}$\n",
    "\n",
    "**Assumption 1:** Observations are **independent and identically distributed (iid)**\n",
    "\n",
    "$$\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) = \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j)\n",
    "$$\n",
    "\n",
    "**Assumption 2:** Bernoulli model with parameter $\\theta \\in [0, 1]$ for the observations\n",
    "\n",
    "$$\n",
    "p(x_i|\\theta, \\mathcal{M}_j) = \\theta^{x_i} (1- \\theta)^{1-x_i}\n",
    "$$\n",
    "\n",
    "> What is the MLE of $\\theta~$?\n",
    "\n",
    "**Trick of the trade:** The arg maximum of $p(x)$ is the same as $\\log p(x)$\n",
    "\n",
    "With this we can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\log p(\\mathcal{D}| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Finally we can take the derivate, set it to zero, and get the MLE \n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N} \\sum_{i=1}^N x_i\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priors and Maximum a Posteriori\n",
    "\n",
    "Let's lift the assumption that the prior is uniform \n",
    "\n",
    "- We are still looking for a point estimate of $\\theta~$ \n",
    "- We keep the *iid* assumption and we consider the \"log trick\"\n",
    "\n",
    "We can write\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat \\theta &= \\text{arg} \\max_\\theta \\log p(\\theta|\\mathcal{D}, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_\\theta \\sum_{i=1}^N \\log p(x_i| \\theta, \\mathcal{M}_j) + \\log p(\\theta|\\mathcal{M}_j) \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "> This is called the **Maximum a posteriori (MAP)** estimate of $\\theta~ $\n",
    "\n",
    "The MAP estimate corresponds to the mode of $p(\\theta|\\mathcal{D}, \\mathcal{M}_j)$\n",
    "\n",
    "Now, in addition to the model (likelihood), we have to set the prior $p(\\theta)$. This can be a [sensible choice](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix:** [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution)\n",
    "\n",
    "A distribution for $x \\in [0, 1]$, *e.g* probabilities\n",
    "\n",
    "The pdf is \n",
    "\n",
    "$$\n",
    "\\text{Beta}(x|\\alpha, \\beta) = \\frac{x^{\\alpha-1} (1-x)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where $B(x,y) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$ and $\\Gamma(x)$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function)\n",
    "\n",
    "For $\\alpha=\\beta=1$ we get the Uniform distribution in $[0, 1]$\n",
    "\n",
    "Let's see it for different values of $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(a, b, x=np.linspace(0,1,num=100)):\n",
    "    dist = scipy.stats.beta(a, b)\n",
    "    return hv.Curve((x, dist.pdf(x)), 'x', 'PDF', label='Beta distribution,')\n",
    "\n",
    "hmap = hv.HoloMap(kdims=['alpha', 'beta'])\n",
    "for a in [0.5, 1, 2, 3, 10]:\n",
    "    for b in [0.5, 1, 2, 3, 10]:\n",
    "        hmap[(a,b)] = plot_distribution(a, b)\n",
    "\n",
    "hmap.opts(hv.opts.Curve(width=500, height=300, ylim=(0, 5), tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** MAP for the coin\n",
    "\n",
    "We will use a Beta prior for $\\theta ~$\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "Omitting the terms that do not depend on $\\theta~$ we get the MAP \n",
    "\n",
    "$$\n",
    "\\hat \\theta= \\text{arg} \\max_\\theta \\sum_{i=1}^N x_i \\log (\\theta) + (1 -x_i) \\log(1-\\theta) +(\\alpha -1) \\log(\\theta) + ( \\beta -1) \\log(1-\\theta) \n",
    "$$\n",
    "\n",
    "and by setting the derivative to zero we obtain\n",
    "\n",
    "$$\n",
    "\\hat \\theta = \\frac{1}{N+\\alpha - \\beta} \\left(\\alpha -1 + \\sum_{i=1}^N x_i\\right)\n",
    "$$\n",
    "\n",
    "Note that it reduces to the MLE for $\\alpha=\\beta=1$ (uniform)\n",
    "\n",
    "> If we know something about the coin before observing the data we add it through $\\alpha$ and $\\beta$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian inference\n",
    "\n",
    "With MLE we get point estimates\n",
    "\n",
    "> How good are these estimates? Can we trust them? What is their uncertainty?\n",
    "\n",
    "Following a frequentist approach we answer this through confidence intervals/bootstrap\n",
    "\n",
    "In a \"full\" bayesian approach we select likelihood/prior and aim for the posterior of $\\theta~$,\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{p(\\mathcal{D}| \\theta, \\mathcal{M}_j) p(\\theta|\\mathcal{M}_j)}{p(\\mathcal{D}|\\mathcal{M}_j)}\n",
    "$$\n",
    "\n",
    "> If we have the posterior we know everything about $\\theta~$\n",
    "\n",
    "But, how do we get the posterior?\n",
    "\n",
    "**Simple case: Analytical posterior**\n",
    "\n",
    "In some \"very special cases\" the posterior is analytically tractable\n",
    "\n",
    "Enter the [**conjugate priors**](https://en.wikipedia.org/wiki/Conjugate_prior#Table_of_conjugate_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Posterior for the coin\n",
    "\n",
    "The likelihood of the coin (Bernoulli) is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "p(\\mathcal{D}|\\theta, \\mathcal{M}_j) &= \\prod_{i=1}^N p(x_i|\\theta, \\mathcal{M}_j) \\nonumber \\\\\n",
    "&= \\prod_{i=1}^N \\theta^{x_i} (1-\\theta)^{1-x_i} \\nonumber \\\\\n",
    "&= \\theta^{\\sum_i x_i}(1-\\theta)^{N-\\sum_i x_i} \\nonumber \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The prior is Beta\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{M}_j) = \\text{Beta}(\\theta| \\alpha , \\beta) = \\frac{\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "The posterior is\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\frac{1}{Z} \\theta^{\\alpha +\\sum_i x_i - 1}(1-\\theta)^{\\beta +N-\\sum_i x_i-1},\n",
    "$$\n",
    "where $Z$ is a normalizing constant\n",
    "\n",
    "We can recognize that the posterior is also Beta:\n",
    "\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}, \\mathcal{M}_j) = \\text{Beta}(\\theta| \\hat \\alpha , \\hat \\beta),\n",
    "$$\n",
    "\n",
    "with $\\hat \\alpha= \\alpha +\\sum_i x_i$ and $\\hat \\beta= \\beta +N-\\sum_i x_i$\n",
    "\n",
    "> We say that Beta is conjugate to the Bernoulli distribution: It produces a Beta posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Move the sliders to change $\\alpha$, $\\beta$ and the number of coins observed\n",
    "\n",
    "How many coins do we need to observe so that the posterior gets close to $p=.7$?\n",
    "\n",
    "What is the influence of $\\alpha$ and $\\beta$ when $N$ is low? And when $N$ is high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coins = scipy.stats.bernoulli.rvs(p=0.7, size=1000, random_state=1234) # True parameter is 0.7\n",
    "x = np.linspace(0, 1, num=100)\n",
    "hmap1 = hv.HoloMap(kdims=['N'])\n",
    "hmap2 = hv.HoloMap(kdims=['N', 'alpha', 'beta'])\n",
    "for N in [1, 2, 5, 10, 20, 50, 100, 200, 500]:\n",
    "    heads = np.sum(coins[:N]) \n",
    "    hmap1[N] = hv.Bars((['head','tail'], [heads, N-heads]), 'x', 'Histogram', label='Coins')\n",
    "    for a in [0.5, 2, 10]:\n",
    "        for b in [0.5, 2, 10]:\n",
    "            prior = scipy.stats.beta(a, b)\n",
    "            posterior = scipy.stats.beta(a + heads, b + N - heads)\n",
    "            hprior = hv.Curve((x, prior.pdf(x)), 'x', 'PDF', group='Distribution', label='prior')\n",
    "            hposterior = hv.Curve((x, posterior.pdf(x)), 'x', 'PDF', group='Distribution', label='posterior')\n",
    "            hmap2[(N, a, b)] = hprior*hposterior\n",
    "\n",
    "#hv.output(widget_location='bottom')\n",
    "(hmap1+hmap2).opts(hv.opts.Bars(width=300, height=300),\n",
    "                   hv.opts.Curve(width=400, height=300, ylim=(0, 5), tools=['hover']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian approach online problems are just updates to the posterior, as the following animation shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, num=100)\n",
    "hmap1 = hv.HoloMap(kdims=['Iteration'])\n",
    "hmap2 = hv.HoloMap(kdims=['Iteration'])\n",
    "\n",
    "a = b = 1 # prior belief\n",
    "for k, coin in enumerate(coins[:100]):\n",
    "    hmap1[k] = hv.Bars((['head','tail'], [a-1, b-1]), 'x', 'Histogram', label='Coins')\n",
    "    hmap2[k] = hv.Curve((x, scipy.stats.beta(a, b).pdf(x)), 'x', 'PDF', label='Posterior')\n",
    "    # posterior updates\n",
    "    a += coin\n",
    "    b += 1 - coin\n",
    "    \n",
    "(hmap1+hmap2).opts(hv.opts.Bars(width=300, height=300),\n",
    "                   hv.opts.Curve(width=400, height=300, ylim=(0, 5)))\n",
    "hv.output((hmap1+hmap2), holomap='gif', fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What  if I can't get an analytical posterior?\n",
    "\n",
    "In many cases the denominator in the posterior \n",
    "\n",
    "$$\n",
    "p(\\mathcal{D} | \\mathcal{M_j}) = \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "$$\n",
    "\n",
    "is intractable\n",
    "\n",
    "The options are to\n",
    "\n",
    "1. Approximation based: Variational Inference (VI)\n",
    "1. Sampling based: Markov Chain Monte Carlo (MCMC) \n",
    "\n",
    "We will review how to implement both using `pyro` in the next chapter of this course \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Inference: Comparing models\n",
    "\n",
    "Using Bayes theorem we can express the posterior probability of a given model as\n",
    "\n",
    "$$\n",
    "p(\\mathcal{M_j} | \\mathcal{D}) = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D})}\n",
    "$$\n",
    "\n",
    "> $p(\\mathcal{D} | \\mathcal{M_j})$ is called the **evidence**  or the **marginal likelihood** for $\\mathcal{M_j}$\n",
    "\n",
    "The evidence was ignored in level 1 inference (normalizing constant) but in this level is key!\n",
    "\n",
    "If we want to compare two models we can compute the ratio between posteriors \n",
    "\n",
    "$$\n",
    "\\frac{p(\\mathcal{M_j} | \\mathcal{D})}{p(\\mathcal{M_k} | \\mathcal{D})} = \\frac{p(\\mathcal{D} | \\mathcal{M_j})  p(\\mathcal{M_j})}{p(\\mathcal{D} | \\mathcal{M_k})  p(\\mathcal{M_k})}\n",
    "$$\n",
    "\n",
    "- We may ignore the priors if we consider the models to be equally probable\n",
    "- or we can use the priors to favor simpler models: **Occam Razor**\n",
    "\n",
    "If there are many models and we care only for the most probable we can write\n",
    "\n",
    "$$\n",
    "\\mathcal{M}^* = \\text{arg} \\max_j p(\\mathcal{M_j} | \\mathcal{D}) \n",
    "$$\n",
    "\n",
    "Using Bayes Theorem and assuming that all models are equally probable (uniform prior)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{M}^* &= \\text{arg} \\max_j p(\\mathcal{D} | \\mathcal{M_j}) \\nonumber \\\\\n",
    "&= \\text{arg} \\max_j \\int p(\\mathcal{D} | \\theta, \\mathcal{M_j}) p(\\theta|\\mathcal{M_j}) d \\theta\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-study and recommended reading\n",
    "\n",
    "- More on [Frequentism vs Bayesianism](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/)\n",
    "- More on level 2 inference: [Chapter 28 of D. Mackay's book](http://www.inference.org.uk/mackay/itprnn/book.html) and [Chapter 12 of D.Barber's book]()\n",
    "- More on sampling and MCMC: [Chapter 27 of D. Barber's book](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
